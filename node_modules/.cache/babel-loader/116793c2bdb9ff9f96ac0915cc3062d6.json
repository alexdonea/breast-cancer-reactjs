{"ast":null,"code":"\"use strict\";\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nvar __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n\n    return extendStatics(d, b);\n  };\n\n  return function (d, b) {\n    extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n    label: 0,\n    sent: function () {\n      if (t[0] & 1) throw t[1];\n      return t[1];\n    },\n    trys: [],\n    ops: []\n  },\n      f,\n      y,\n      t,\n      g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n\n    while (_) try {\n      if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n      if (y = 0, t) op = [op[0] & 2, t.value];\n\n      switch (op[0]) {\n        case 0:\n        case 1:\n          t = op;\n          break;\n\n        case 4:\n          _.label++;\n          return {\n            value: op[1],\n            done: false\n          };\n\n        case 5:\n          _.label++;\n          y = op[1];\n          op = [0];\n          continue;\n\n        case 7:\n          op = _.ops.pop();\n\n          _.trys.pop();\n\n          continue;\n\n        default:\n          if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n            _ = 0;\n            continue;\n          }\n\n          if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n            _.label = op[1];\n            break;\n          }\n\n          if (op[0] === 6 && _.label < t[1]) {\n            _.label = t[1];\n            t = op;\n            break;\n          }\n\n          if (t && _.label < t[2]) {\n            _.label = t[2];\n\n            _.ops.push(op);\n\n            break;\n          }\n\n          if (t[2]) _.ops.pop();\n\n          _.trys.pop();\n\n          continue;\n      }\n\n      op = body.call(thisArg, _);\n    } catch (e) {\n      op = [6, e];\n      y = 0;\n    } finally {\n      f = t = 0;\n    }\n\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar tensor_format_1 = require(\"./tensor_format\");\n\nvar util = require(\"./util\");\n\nvar util_1 = require(\"./util\");\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n */\n\n/** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\nvar TensorBuffer =\n/** @class */\nfunction () {\n  function TensorBuffer(shape, dtype, values) {\n    var _this = this;\n\n    this.dtype = dtype;\n    this.shape = shape.slice();\n    this.size = util.sizeFromShape(shape);\n\n    if (values != null) {\n      var n_1 = values.length;\n      util.assert(n_1 === this.size, function () {\n        return \"Length of values '\" + n_1 + \"' does not match the size \" + (\"inferred by the shape '\" + _this.size + \"'.\");\n      });\n    }\n\n    if (dtype === 'complex64') {\n      throw new Error(\"complex64 dtype TensorBuffers are not supported. Please create \" + \"a TensorBuffer for the real and imaginary parts separately and \" + \"call tf.complex(real, imag).\");\n    }\n\n    this.values = values || util.getArrayFromDType(dtype, this.size);\n    this.strides = util_1.computeStrides(shape);\n  }\n  /**\n   * Sets a value in the buffer at a given location.\n   *\n   * @param value The value to set.\n   * @param locs  The location indices.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Creation'} */\n\n\n  TensorBuffer.prototype.set = function (value) {\n    var _this = this;\n\n    var locs = [];\n\n    for (var _i = 1; _i < arguments.length; _i++) {\n      locs[_i - 1] = arguments[_i];\n    }\n\n    if (locs.length === 0) {\n      locs = [0];\n    }\n\n    util.assert(locs.length === this.rank, function () {\n      return \"The number of provided coordinates (\" + locs.length + \") must \" + (\"match the rank (\" + _this.rank + \")\");\n    });\n    var index = this.locToIndex(locs);\n    this.values[index] = value;\n  };\n  /**\n   * Returns the value in the buffer at the provided location.\n   *\n   * @param locs The location indices.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Creation'} */\n\n\n  TensorBuffer.prototype.get = function () {\n    var locs = [];\n\n    for (var _i = 0; _i < arguments.length; _i++) {\n      locs[_i] = arguments[_i];\n    }\n\n    if (locs.length === 0) {\n      locs = [0];\n    }\n\n    var i = 0;\n\n    for (var _a = 0, locs_1 = locs; _a < locs_1.length; _a++) {\n      var loc = locs_1[_a];\n\n      if (loc < 0 || loc >= this.shape[i]) {\n        var msg = \"Requested out of range element at \" + locs + \". \" + (\"  Buffer shape=\" + this.shape);\n        throw new Error(msg);\n      }\n\n      i++;\n    }\n\n    var index = locs[locs.length - 1];\n\n    for (var i_1 = 0; i_1 < locs.length - 1; ++i_1) {\n      index += this.strides[i_1] * locs[i_1];\n    }\n\n    return this.values[index];\n  };\n\n  TensorBuffer.prototype.locToIndex = function (locs) {\n    if (this.rank === 0) {\n      return 0;\n    } else if (this.rank === 1) {\n      return locs[0];\n    }\n\n    var index = locs[locs.length - 1];\n\n    for (var i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n\n    return index;\n  };\n\n  TensorBuffer.prototype.indexToLoc = function (index) {\n    if (this.rank === 0) {\n      return [];\n    } else if (this.rank === 1) {\n      return [index];\n    }\n\n    var locs = new Array(this.shape.length);\n\n    for (var i = 0; i < locs.length - 1; ++i) {\n      locs[i] = Math.floor(index / this.strides[i]);\n      index -= locs[i] * this.strides[i];\n    }\n\n    locs[locs.length - 1] = index;\n    return locs;\n  };\n\n  Object.defineProperty(TensorBuffer.prototype, \"rank\", {\n    get: function () {\n      return this.shape.length;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  /**\n   * Creates an immutable `tf.Tensor` object from the buffer.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Creation'} */\n\n  TensorBuffer.prototype.toTensor = function () {\n    return trackerFn().makeTensor(this.values, this.shape, this.dtype);\n  };\n\n  return TensorBuffer;\n}();\n\nexports.TensorBuffer = TensorBuffer; // For tracking tensor creation and disposal.\n\nvar trackerFn = null; // Used by chaining methods to call into ops.\n\nvar opHandler = null; // Used to warn about deprecated methods.\n\nvar deprecationWarningFn = null; // This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n\n[deprecationWarningFn];\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\n\nfunction setTensorTracker(fn) {\n  trackerFn = fn;\n}\n\nexports.setTensorTracker = setTensorTracker;\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op\n * handler.\n */\n\nfunction setOpHandler(handler) {\n  opHandler = handler;\n}\n\nexports.setOpHandler = setOpHandler;\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\n\nfunction setDeprecationWarningFn(fn) {\n  deprecationWarningFn = fn;\n}\n\nexports.setDeprecationWarningFn = setDeprecationWarningFn;\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n */\n\n/** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\nvar Tensor =\n/** @class */\nfunction () {\n  function Tensor(shape, dtype, dataId, id) {\n    /** Whether this tensor has been globally kept. */\n    this.kept = false;\n    this.isDisposedInternal = false;\n    this.shape = shape.slice();\n    this.dtype = dtype || 'float32';\n    this.size = util.sizeFromShape(shape);\n    this.strides = util_1.computeStrides(shape);\n    this.dataId = dataId;\n    this.id = id;\n    this.rankType = this.rank < 5 ? this.rank.toString() : 'higher';\n  }\n  /** Flatten a Tensor to a 1D array. */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.flatten = function () {\n    this.throwIfDisposed();\n    return this.as1D();\n  };\n  /** Converts a size-1 `tf.Tensor` to a `tf.Scalar`. */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.asScalar = function () {\n    this.throwIfDisposed();\n    util.assert(this.size === 1, function () {\n      return 'The array must have only 1 element.';\n    });\n    return this.reshape([]);\n  };\n  /** Converts a `tf.Tensor` to a `tf.Tensor1D`. */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.as1D = function () {\n    this.throwIfDisposed();\n    return this.reshape([this.size]);\n  };\n  /**\n   * Converts a `tf.Tensor` to a `tf.Tensor2D`.\n   *\n   * @param rows Number of rows in `tf.Tensor2D`.\n   * @param columns Number of columns in `tf.Tensor2D`.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.as2D = function (rows, columns) {\n    this.throwIfDisposed();\n    return this.reshape([rows, columns]);\n  };\n  /**\n   * Converts a `tf.Tensor` to a `tf.Tensor3D`.\n   *\n   * @param rows Number of rows in `tf.Tensor3D`.\n   * @param columns Number of columns in `tf.Tensor3D`.\n   * @param depth Depth of `tf.Tensor3D`.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.as3D = function (rows, columns, depth) {\n    this.throwIfDisposed();\n    return this.reshape([rows, columns, depth]);\n  };\n  /**\n   * Converts a `tf.Tensor` to a `tf.Tensor4D`.\n   *\n   * @param rows Number of rows in `tf.Tensor4D`.\n   * @param columns Number of columns in `tf.Tensor4D`.\n   * @param depth Depth of `tf.Tensor4D`.\n   * @param depth2 4th dimension of `tf.Tensor4D`.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.as4D = function (rows, columns, depth, depth2) {\n    this.throwIfDisposed();\n    return this.reshape([rows, columns, depth, depth2]);\n  };\n  /**\n   * Converts a `tf.Tensor` to a `tf.Tensor5D`.\n   *\n   * @param rows Number of rows in `tf.Tensor5D`.\n   * @param columns Number of columns in `tf.Tensor5D`.\n   * @param depth Depth of `tf.Tensor5D`.\n   * @param depth2 4th dimension of `tf.Tensor5D`.\n   * @param depth3 5th dimension of 'tf.Tensor5D'\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.as5D = function (rows, columns, depth, depth2, depth3) {\n    this.throwIfDisposed();\n    return this.reshape([rows, columns, depth, depth2, depth3]);\n  };\n  /**\n   * Casts a `tf.Tensor` to a specified dtype.\n   *\n   * @param dtype Data-type to cast the tensor to.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.asType = function (dtype) {\n    this.throwIfDisposed();\n    return opHandler.cast(this, dtype);\n  };\n\n  Object.defineProperty(Tensor.prototype, \"rank\", {\n    get: function () {\n      return this.shape.length;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  /**\n   * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n  Tensor.prototype.buffer = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var vals;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , this.data()];\n\n          case 1:\n            vals = _a.sent();\n            return [2\n            /*return*/\n            , opHandler.buffer(this.shape, this.dtype, vals)];\n        }\n      });\n    });\n  };\n  /** Returns a `tf.TensorBuffer` that holds the underlying data. */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.bufferSync = function () {\n    return opHandler.buffer(this.shape, this.dtype, this.dataSync());\n  };\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * asynchronously.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.array = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var vals;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , this.data()];\n\n          case 1:\n            vals = _a.sent();\n            return [2\n            /*return*/\n            , util_1.toNestedArray(this.shape, vals)];\n        }\n      });\n    });\n  };\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * synchronously.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.arraySync = function () {\n    return util_1.toNestedArray(this.shape, this.dataSync());\n  };\n  /**\n   * Asynchronously downloads the values from the `tf.Tensor`. Returns a\n   * promise of `TypedArray` that resolves when the computation has finished.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.data = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var data, bytes;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            this.throwIfDisposed();\n            data = trackerFn().read(this.dataId);\n            if (!(this.dtype === 'string')) return [3\n            /*break*/\n            , 2];\n            return [4\n            /*yield*/\n            , data];\n\n          case 1:\n            bytes = _a.sent();\n\n            try {\n              return [2\n              /*return*/\n              , bytes.map(function (b) {\n                return util.decodeString(b);\n              })];\n            } catch (_b) {\n              throw new Error('Failed to decode the string bytes into utf-8. ' + 'To get the original bytes, call tensor.bytes().');\n            }\n\n            _a.label = 2;\n\n          case 2:\n            return [2\n            /*return*/\n            , data];\n        }\n      });\n    });\n  };\n  /**\n   * Synchronously downloads the values from the `tf.Tensor`. This blocks the\n   * UI thread until the values are ready, which can cause performance issues.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.dataSync = function () {\n    this.throwIfDisposed();\n    var data = trackerFn().readSync(this.dataId);\n\n    if (this.dtype === 'string') {\n      try {\n        return data.map(function (b) {\n          return util.decodeString(b);\n        });\n      } catch (_a) {\n        throw new Error('Failed to decode the string bytes into utf-8. ' + 'To get the original bytes, call tensor.bytes().');\n      }\n    }\n\n    return data;\n  };\n  /** Returns the underlying bytes of the tensor's data. */\n\n\n  Tensor.prototype.bytes = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var data;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            this.throwIfDisposed();\n            return [4\n            /*yield*/\n            , trackerFn().read(this.dataId)];\n\n          case 1:\n            data = _a.sent();\n\n            if (this.dtype === 'string') {\n              return [2\n              /*return*/\n              , data];\n            } else {\n              return [2\n              /*return*/\n              , new Uint8Array(data.buffer)];\n            }\n\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\n   * Disposes `tf.Tensor` from memory.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.dispose = function () {\n    if (this.isDisposed) {\n      return;\n    }\n\n    trackerFn().disposeTensor(this);\n    this.isDisposedInternal = true;\n  };\n\n  Object.defineProperty(Tensor.prototype, \"isDisposed\", {\n    get: function () {\n      return this.isDisposedInternal;\n    },\n    enumerable: true,\n    configurable: true\n  });\n\n  Tensor.prototype.throwIfDisposed = function () {\n    if (this.isDisposed) {\n      throw new Error(\"Tensor is disposed.\");\n    }\n  };\n  /** Casts the array to type `float32` */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.toFloat = function () {\n    return this.asType('float32');\n  };\n  /** Casts the array to type `int32` */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.toInt = function () {\n    return this.asType('int32');\n  };\n  /** Casts the array to type `bool` */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.toBool = function () {\n    return this.asType('bool');\n  };\n  /**\n   * Prints the `tf.Tensor`. See `tf.print` for details.\n   *\n   * @param verbose Whether to print verbose information about the tensor,\n   *    including dtype and size.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.print = function (verbose) {\n    if (verbose === void 0) {\n      verbose = false;\n    }\n\n    return opHandler.print(this, verbose);\n  };\n  /**\n   * Reshapes the tensor into the provided shape.\n   * See `tf.reshape` for more details.\n   *\n   * @param newShape An array of integers defining the output tensor shape.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.reshape = function (newShape) {\n    this.throwIfDisposed();\n    return opHandler.reshape(this, newShape);\n  };\n  /**\n   * Reshapes the tensor into the shape of the provided tensor.\n   *\n   * @param x The tensor of required shape.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.reshapeAs = function (x) {\n    this.throwIfDisposed();\n    return this.reshape(x.shape);\n  };\n  /**\n   * Returns a `tf.Tensor` that has expanded rank, by inserting a dimension\n   * into the tensor's shape. See `tf.expandDims` for details.\n   *\n   * @param axis The dimension index at which to insert shape of 1. Defaults to\n   *     0 (the first dimension).\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.expandDims = function (axis) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    return opHandler.expandDims(this, axis);\n  };\n  /**\n   * Returns the cumulative sum of the `tf.Tensor` along `axis`.\n   *\n   * @param axis The axis along which to sum. Optional. Defaults to 0.\n   * @param exclusive Whether to perform exclusive cumulative sum. Defaults to\n   *    false. If set to true then the sum of each tensor entry does not\n   * include its own value, but only the values previous to it along the\n   * specified axis.\n   * @param reverse Whether to sum in the opposite direction. Defaults to\n   *    false.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.cumsum = function (axis, exclusive, reverse) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    if (exclusive === void 0) {\n      exclusive = false;\n    }\n\n    if (reverse === void 0) {\n      reverse = false;\n    }\n\n    return opHandler.cumsum(this, axis, exclusive, reverse);\n  };\n  /**\n   * Returns a `tf.Tensor` with dimensions of size 1 removed from the shape.\n   * See `tf.squeeze` for more details.\n   *\n   * @param axis A list of numbers. If specified, only squeezes the\n   *    dimensions listed. The dimension index starts at 0. It is an error to\n   *    squeeze a dimension that is not 1.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.squeeze = function (axis) {\n    this.throwIfDisposed();\n    return opHandler.squeeze(this, axis);\n  };\n  /** Returns a copy of the tensor. See `tf.clone` for details. */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.clone = function () {\n    this.throwIfDisposed();\n    return opHandler.clone(this);\n  };\n\n  Tensor.prototype.oneHot = function (depth, onValue, offValue) {\n    this.throwIfDisposed();\n    return opHandler.oneHot(this, depth, onValue, offValue);\n  };\n  /**\n   * Returns a human-readable description of the tensor. Useful for logging.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Tensor.prototype.toString = function (verbose) {\n    if (verbose === void 0) {\n      verbose = false;\n    }\n\n    var vals = this.dataSync();\n    return tensor_format_1.tensorToString(vals, this.shape, this.dtype, verbose);\n  }; // Below is chain API that is not exposed to docs to avoid repetition. To\n  // expose a method, move it above this comment and add @doc and jsdoc.\n\n\n  Tensor.prototype.tile = function (reps) {\n    this.throwIfDisposed();\n    return opHandler.tile(this, reps);\n  };\n\n  Tensor.prototype.gather = function (indices, axis) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.gather(this, indices, axis);\n  };\n\n  Tensor.prototype.matMul = function (b, transposeA, transposeB) {\n    if (transposeA === void 0) {\n      transposeA = false;\n    }\n\n    if (transposeB === void 0) {\n      transposeB = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.matMul(this, b, transposeA, transposeB);\n  };\n\n  Tensor.prototype.dot = function (b) {\n    this.throwIfDisposed();\n    return opHandler.dot(this, b);\n  };\n\n  Tensor.prototype.norm = function (ord, axis, keepDims) {\n    if (ord === void 0) {\n      ord = 'euclidean';\n    }\n\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    if (keepDims === void 0) {\n      keepDims = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.norm(this, ord, axis, keepDims);\n  };\n\n  Tensor.prototype.slice = function (begin, size) {\n    this.throwIfDisposed();\n    return opHandler.slice(this, begin, size);\n  };\n\n  Tensor.prototype.reverse = function (axis) {\n    this.throwIfDisposed();\n    return opHandler.reverse(this, axis);\n  };\n\n  Tensor.prototype.concat = function (x, axis) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    this.throwIfDisposed();\n\n    if (x instanceof Tensor) {\n      x = [x];\n    }\n\n    return opHandler.concat([this].concat(x), axis);\n  };\n\n  Tensor.prototype.split = function (numOrSizeSplits, axis) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.split(this, numOrSizeSplits, axis);\n  };\n\n  Tensor.prototype.stack = function (x, axis) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    return opHandler.stack([this, x], axis);\n  };\n\n  Tensor.prototype.unstack = function (axis) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    return opHandler.unstack(this, axis);\n  };\n\n  Tensor.prototype.pad = function (paddings, constantValue) {\n    if (constantValue === void 0) {\n      constantValue = 0;\n    }\n\n    return opHandler.pad(this, paddings, constantValue);\n  };\n  /**\n   * @deprecated Use `tf.batchNorm` instead, and note the positional argument\n   *     change of scale, offset, and varianceEpsilon.\n   */\n\n\n  Tensor.prototype.batchNormalization = function (mean, variance, varianceEpsilon, scale, offset) {\n    if (varianceEpsilon === void 0) {\n      varianceEpsilon = .001;\n    }\n\n    deprecationWarningFn('tf.batchNormalization() is going away. ' + 'Use tf.batchNorm() instead, and note the positional argument change ' + 'of scale, offset, and varianceEpsilon');\n    return this.batchNorm(mean, variance, offset, scale, varianceEpsilon);\n  };\n\n  Tensor.prototype.batchNorm = function (mean, variance, offset, scale, varianceEpsilon) {\n    if (varianceEpsilon === void 0) {\n      varianceEpsilon = .001;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.batchNorm(this, mean, variance, offset, scale, varianceEpsilon);\n  }; // Reduction ops.\n\n\n  Tensor.prototype.all = function (axis, keepDims) {\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    if (keepDims === void 0) {\n      keepDims = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.all(this, axis, keepDims);\n  };\n\n  Tensor.prototype.any = function (axis, keepDims) {\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    if (keepDims === void 0) {\n      keepDims = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.any(this, axis, keepDims);\n  };\n\n  Tensor.prototype.logSumExp = function (axis, keepDims) {\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    if (keepDims === void 0) {\n      keepDims = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.logSumExp(this, axis, keepDims);\n  };\n\n  Tensor.prototype.sum = function (axis, keepDims) {\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    if (keepDims === void 0) {\n      keepDims = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.sum(this, axis, keepDims);\n  };\n\n  Tensor.prototype.prod = function (axis, keepDims) {\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    if (keepDims === void 0) {\n      keepDims = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.prod(this, axis, keepDims);\n  };\n\n  Tensor.prototype.mean = function (axis, keepDims) {\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    if (keepDims === void 0) {\n      keepDims = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.mean(this, axis, keepDims);\n  };\n\n  Tensor.prototype.min = function (axis, keepDims) {\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    if (keepDims === void 0) {\n      keepDims = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.min(this, axis, keepDims);\n  };\n\n  Tensor.prototype.max = function (axis, keepDims) {\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    if (keepDims === void 0) {\n      keepDims = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.max(this, axis, keepDims);\n  };\n\n  Tensor.prototype.argMin = function (axis) {\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.argMin(this, axis);\n  };\n\n  Tensor.prototype.argMax = function (axis) {\n    if (axis === void 0) {\n      axis = null;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.argMax(this, axis);\n  }; // Transformations\n\n\n  Tensor.prototype.cast = function (dtype) {\n    this.throwIfDisposed();\n    return opHandler.cast(this, dtype);\n  }; // Binary ops.\n\n\n  Tensor.prototype.add = function (x) {\n    this.throwIfDisposed();\n    return opHandler.add(this, x);\n  };\n\n  Tensor.prototype.addStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.addStrict(this, x);\n  };\n\n  Tensor.prototype.atan2 = function (x) {\n    this.throwIfDisposed();\n    return opHandler.atan2(this, x);\n  };\n\n  Tensor.prototype.sub = function (x) {\n    this.throwIfDisposed();\n    return opHandler.sub(this, x);\n  };\n\n  Tensor.prototype.subStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.subStrict(this, x);\n  };\n\n  Tensor.prototype.pow = function (exp) {\n    this.throwIfDisposed();\n    return opHandler.pow(this, exp);\n  };\n\n  Tensor.prototype.powStrict = function (exp) {\n    this.throwIfDisposed();\n    return opHandler.powStrict(this, exp);\n  };\n\n  Tensor.prototype.mul = function (x) {\n    this.throwIfDisposed();\n    return opHandler.mul(this, x);\n  };\n\n  Tensor.prototype.mulStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.mulStrict(this, x);\n  };\n\n  Tensor.prototype.div = function (x) {\n    this.throwIfDisposed();\n    return opHandler.div(this, x);\n  };\n\n  Tensor.prototype.floorDiv = function (x) {\n    this.throwIfDisposed();\n    return opHandler.floorDiv(this, x);\n  };\n\n  Tensor.prototype.divStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.divStrict(this, x);\n  };\n\n  Tensor.prototype.minimum = function (x) {\n    this.throwIfDisposed();\n    return opHandler.minimum(this, x);\n  };\n\n  Tensor.prototype.minimumStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.minimumStrict(this, x);\n  };\n\n  Tensor.prototype.maximum = function (x) {\n    this.throwIfDisposed();\n    return opHandler.maximum(this, x);\n  };\n\n  Tensor.prototype.maximumStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.maximumStrict(this, x);\n  };\n\n  Tensor.prototype.mod = function (x) {\n    this.throwIfDisposed();\n    return opHandler.mod(this, x);\n  };\n\n  Tensor.prototype.modStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.modStrict(this, x);\n  };\n\n  Tensor.prototype.squaredDifference = function (x) {\n    this.throwIfDisposed();\n    return opHandler.squaredDifference(this, x);\n  };\n\n  Tensor.prototype.squaredDifferenceStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.squaredDifferenceStrict(this, x);\n  };\n\n  Tensor.prototype.transpose = function (perm) {\n    this.throwIfDisposed();\n    return opHandler.transpose(this, perm);\n  }; // Compare ops.\n\n\n  Tensor.prototype.notEqual = function (x) {\n    this.throwIfDisposed();\n    return opHandler.notEqual(this, x);\n  };\n\n  Tensor.prototype.notEqualStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.notEqualStrict(this, x);\n  };\n\n  Tensor.prototype.less = function (x) {\n    this.throwIfDisposed();\n    return opHandler.less(this, x);\n  };\n\n  Tensor.prototype.lessStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.lessStrict(this, x);\n  };\n\n  Tensor.prototype.equal = function (x) {\n    this.throwIfDisposed();\n    return opHandler.equal(this, x);\n  };\n\n  Tensor.prototype.equalStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.equalStrict(this, x);\n  };\n\n  Tensor.prototype.lessEqual = function (x) {\n    this.throwIfDisposed();\n    return opHandler.lessEqual(this, x);\n  };\n\n  Tensor.prototype.lessEqualStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.lessEqualStrict(this, x);\n  };\n\n  Tensor.prototype.greater = function (x) {\n    this.throwIfDisposed();\n    return opHandler.greater(this, x);\n  };\n\n  Tensor.prototype.greaterStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.greaterStrict(this, x);\n  };\n\n  Tensor.prototype.greaterEqual = function (x) {\n    this.throwIfDisposed();\n    return opHandler.greaterEqual(this, x);\n  };\n\n  Tensor.prototype.greaterEqualStrict = function (x) {\n    this.throwIfDisposed();\n    return opHandler.greaterEqualStrict(this, x);\n  }; // Compare ops.\n\n\n  Tensor.prototype.logicalAnd = function (x) {\n    this.throwIfDisposed();\n    return opHandler.logicalAnd(this, x);\n  };\n\n  Tensor.prototype.logicalOr = function (x) {\n    this.throwIfDisposed();\n    return opHandler.logicalOr(this, x);\n  };\n\n  Tensor.prototype.logicalNot = function () {\n    this.throwIfDisposed();\n    return opHandler.logicalNot(this);\n  };\n\n  Tensor.prototype.logicalXor = function (x) {\n    this.throwIfDisposed();\n    return opHandler.logicalXor(this, x);\n  };\n\n  Tensor.prototype.where = function (condition, x) {\n    this.throwIfDisposed();\n    return opHandler.where(condition, this, x);\n  }; // Unary ops.\n\n\n  Tensor.prototype.neg = function () {\n    this.throwIfDisposed();\n    return opHandler.neg(this);\n  };\n\n  Tensor.prototype.ceil = function () {\n    this.throwIfDisposed();\n    return opHandler.ceil(this);\n  };\n\n  Tensor.prototype.floor = function () {\n    this.throwIfDisposed();\n    return opHandler.floor(this);\n  };\n\n  Tensor.prototype.sign = function () {\n    this.throwIfDisposed();\n    return opHandler.sign(this);\n  };\n\n  Tensor.prototype.isNaN = function () {\n    this.throwIfDisposed();\n    return opHandler.isNaN(this);\n  };\n\n  Tensor.prototype.isInf = function () {\n    this.throwIfDisposed();\n    return opHandler.isInf(this);\n  };\n\n  Tensor.prototype.isFinite = function () {\n    this.throwIfDisposed();\n    return opHandler.isFinite(this);\n  };\n\n  Tensor.prototype.exp = function () {\n    this.throwIfDisposed();\n    return opHandler.exp(this);\n  };\n\n  Tensor.prototype.expm1 = function () {\n    this.throwIfDisposed();\n    return opHandler.expm1(this);\n  };\n\n  Tensor.prototype.log = function () {\n    this.throwIfDisposed();\n    return opHandler.log(this);\n  };\n\n  Tensor.prototype.log1p = function () {\n    this.throwIfDisposed();\n    return opHandler.log1p(this);\n  };\n\n  Tensor.prototype.sqrt = function () {\n    this.throwIfDisposed();\n    return opHandler.sqrt(this);\n  };\n\n  Tensor.prototype.rsqrt = function () {\n    this.throwIfDisposed();\n    return opHandler.rsqrt(this);\n  };\n\n  Tensor.prototype.square = function () {\n    this.throwIfDisposed();\n    return opHandler.square(this);\n  };\n\n  Tensor.prototype.reciprocal = function () {\n    this.throwIfDisposed();\n    return opHandler.reciprocal(this);\n  };\n\n  Tensor.prototype.abs = function () {\n    this.throwIfDisposed();\n    return opHandler.abs(this);\n  };\n\n  Tensor.prototype.clipByValue = function (min, max) {\n    this.throwIfDisposed();\n    return opHandler.clipByValue(this, min, max);\n  };\n\n  Tensor.prototype.relu = function () {\n    this.throwIfDisposed();\n    return opHandler.relu(this);\n  };\n\n  Tensor.prototype.relu6 = function () {\n    this.throwIfDisposed();\n    return opHandler.relu6(this);\n  };\n\n  Tensor.prototype.elu = function () {\n    this.throwIfDisposed();\n    return opHandler.elu(this);\n  };\n\n  Tensor.prototype.selu = function () {\n    this.throwIfDisposed();\n    return opHandler.selu(this);\n  };\n\n  Tensor.prototype.leakyRelu = function (alpha) {\n    if (alpha === void 0) {\n      alpha = 0.2;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.leakyRelu(this, alpha);\n  };\n\n  Tensor.prototype.prelu = function (alpha) {\n    this.throwIfDisposed();\n    return opHandler.prelu(this, alpha);\n  };\n\n  Tensor.prototype.sigmoid = function () {\n    this.throwIfDisposed();\n    return opHandler.sigmoid(this);\n  };\n\n  Tensor.prototype.logSigmoid = function () {\n    this.throwIfDisposed();\n    return opHandler.logSigmoid(this);\n  };\n\n  Tensor.prototype.softplus = function () {\n    this.throwIfDisposed();\n    return opHandler.softplus(this);\n  };\n\n  Tensor.prototype.zerosLike = function () {\n    this.throwIfDisposed();\n    return opHandler.zerosLike(this);\n  };\n\n  Tensor.prototype.onesLike = function () {\n    this.throwIfDisposed();\n    return opHandler.onesLike(this);\n  };\n\n  Tensor.prototype.sin = function () {\n    this.throwIfDisposed();\n    return opHandler.sin(this);\n  };\n\n  Tensor.prototype.cos = function () {\n    this.throwIfDisposed();\n    return opHandler.cos(this);\n  };\n\n  Tensor.prototype.tan = function () {\n    this.throwIfDisposed();\n    return opHandler.tan(this);\n  };\n\n  Tensor.prototype.asin = function () {\n    this.throwIfDisposed();\n    return opHandler.asin(this);\n  };\n\n  Tensor.prototype.acos = function () {\n    this.throwIfDisposed();\n    return opHandler.acos(this);\n  };\n\n  Tensor.prototype.atan = function () {\n    this.throwIfDisposed();\n    return opHandler.atan(this);\n  };\n\n  Tensor.prototype.sinh = function () {\n    this.throwIfDisposed();\n    return opHandler.sinh(this);\n  };\n\n  Tensor.prototype.cosh = function () {\n    this.throwIfDisposed();\n    return opHandler.cosh(this);\n  };\n\n  Tensor.prototype.tanh = function () {\n    this.throwIfDisposed();\n    return opHandler.tanh(this);\n  };\n\n  Tensor.prototype.asinh = function () {\n    this.throwIfDisposed();\n    return opHandler.asinh(this);\n  };\n\n  Tensor.prototype.acosh = function () {\n    this.throwIfDisposed();\n    return opHandler.acosh(this);\n  };\n\n  Tensor.prototype.atanh = function () {\n    this.throwIfDisposed();\n    return opHandler.atanh(this);\n  };\n\n  Tensor.prototype.erf = function () {\n    this.throwIfDisposed();\n    return opHandler.erf(this);\n  };\n\n  Tensor.prototype.round = function () {\n    this.throwIfDisposed();\n    return opHandler.round(this);\n  };\n\n  Tensor.prototype.step = function (alpha) {\n    if (alpha === void 0) {\n      alpha = 0.0;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.step(this, alpha);\n  };\n\n  Tensor.prototype.softmax = function (dim) {\n    if (dim === void 0) {\n      dim = -1;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.softmax(this, dim);\n  };\n\n  Tensor.prototype.logSoftmax = function (axis) {\n    if (axis === void 0) {\n      axis = -1;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.logSoftmax(this, axis);\n  }; // Image ops.\n\n\n  Tensor.prototype.resizeBilinear = function (newShape2D, alignCorners) {\n    if (alignCorners === void 0) {\n      alignCorners = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.image.resizeBilinear(this, newShape2D, alignCorners);\n  };\n\n  Tensor.prototype.resizeNearestNeighbor = function (newShape2D, alignCorners) {\n    if (alignCorners === void 0) {\n      alignCorners = false;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.image.resizeNearestNeighbor(this, newShape2D, alignCorners);\n  }; // Convolutions.\n\n\n  Tensor.prototype.conv1d = function (filter, stride, pad, dataFormat, dilation, dimRoundingMode) {\n    if (dataFormat === void 0) {\n      dataFormat = 'NWC';\n    }\n\n    if (dilation === void 0) {\n      dilation = 1;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.conv1d(this, filter, stride, pad, dataFormat, dilation, dimRoundingMode);\n  };\n\n  Tensor.prototype.conv2d = function (filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n    if (dataFormat === void 0) {\n      dataFormat = 'NHWC';\n    }\n\n    if (dilations === void 0) {\n      dilations = [1, 1];\n    }\n\n    this.throwIfDisposed();\n    return opHandler.conv2d(this, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n  };\n\n  Tensor.prototype.conv2dTranspose = function (filter, outputShape, strides, pad, dimRoundingMode) {\n    this.throwIfDisposed();\n    return opHandler.conv2dTranspose(this, filter, outputShape, strides, pad, dimRoundingMode);\n  };\n\n  Tensor.prototype.depthwiseConv2D = function (filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n    if (dataFormat === void 0) {\n      dataFormat = 'NHWC';\n    }\n\n    if (dilations === void 0) {\n      dilations = [1, 1];\n    }\n\n    this.throwIfDisposed();\n    return opHandler.depthwiseConv2d(this, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n  };\n\n  Tensor.prototype.separableConv2d = function (depthwiseFilter, pointwiseFilter, strides, pad, dilation, dataFormat) {\n    if (dilation === void 0) {\n      dilation = [1, 1];\n    }\n\n    if (dataFormat === void 0) {\n      dataFormat = 'NHWC';\n    }\n\n    this.throwIfDisposed();\n    return opHandler.separableConv2d(this, depthwiseFilter, pointwiseFilter, strides, pad, dilation, dataFormat);\n  }; // Pooling.\n\n\n  Tensor.prototype.avgPool = function (filterSize, strides, pad, dimRoundingMode) {\n    this.throwIfDisposed();\n    return opHandler.avgPool(this, filterSize, strides, pad, dimRoundingMode);\n  };\n\n  Tensor.prototype.maxPool = function (filterSize, strides, pad, dimRoundingMode) {\n    this.throwIfDisposed();\n    return opHandler.maxPool(this, filterSize, strides, pad, dimRoundingMode);\n  };\n\n  Tensor.prototype.localResponseNormalization = function (radius, bias, alpha, beta) {\n    if (radius === void 0) {\n      radius = 5;\n    }\n\n    if (bias === void 0) {\n      bias = 1;\n    }\n\n    if (alpha === void 0) {\n      alpha = 1;\n    }\n\n    if (beta === void 0) {\n      beta = 0.5;\n    }\n\n    return opHandler.localResponseNormalization(this, radius, bias, alpha, beta);\n  };\n\n  Tensor.prototype.pool = function (windowShape, poolingType, padding, dilationRate, strides) {\n    this.throwIfDisposed();\n    return opHandler.pool(this, windowShape, poolingType, padding, dilationRate, strides);\n  };\n\n  Tensor.prototype.variable = function (trainable, name, dtype) {\n    if (trainable === void 0) {\n      trainable = true;\n    }\n\n    this.throwIfDisposed();\n    return trackerFn().makeVariable(this, trainable, name, dtype);\n  };\n\n  Tensor.prototype.unsortedSegmentSum = function (segmentIds, numSegments) {\n    this.throwIfDisposed();\n    return opHandler.unsortedSegmentSum(this, segmentIds, numSegments);\n  };\n\n  Tensor.prototype.batchToSpaceND = function (blockShape, crops) {\n    this.throwIfDisposed();\n    return opHandler.batchToSpaceND(this, blockShape, crops);\n  };\n\n  Tensor.prototype.spaceToBatchND = function (blockShape, paddings) {\n    this.throwIfDisposed();\n    return opHandler.spaceToBatchND(this, blockShape, paddings);\n  };\n\n  Tensor.prototype.topk = function (k, sorted) {\n    if (k === void 0) {\n      k = 1;\n    }\n\n    if (sorted === void 0) {\n      sorted = true;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.topk(this, k, sorted);\n  };\n\n  Tensor.prototype.stridedSlice = function (begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n    if (beginMask === void 0) {\n      beginMask = 0;\n    }\n\n    if (endMask === void 0) {\n      endMask = 0;\n    }\n\n    if (ellipsisMask === void 0) {\n      ellipsisMask = 0;\n    }\n\n    if (newAxisMask === void 0) {\n      newAxisMask = 0;\n    }\n\n    if (shrinkAxisMask === void 0) {\n      shrinkAxisMask = 0;\n    }\n\n    this.throwIfDisposed();\n    return opHandler.stridedSlice(this, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);\n  };\n\n  Tensor.prototype.depthToSpace = function (blockSize, dataFormat) {\n    this.throwIfDisposed();\n    return opHandler.depthToSpace(this, blockSize, dataFormat);\n  };\n\n  Tensor.prototype.fft = function () {\n    this.throwIfDisposed();\n    return opHandler.spectral.fft(this);\n  };\n\n  Tensor.prototype.ifft = function () {\n    this.throwIfDisposed();\n    return opHandler.spectral.ifft(this);\n  };\n\n  Tensor.prototype.rfft = function () {\n    this.throwIfDisposed();\n    return opHandler.spectral.rfft(this);\n  };\n\n  Tensor.prototype.irfft = function () {\n    this.throwIfDisposed();\n    return opHandler.spectral.irfft(this);\n  };\n\n  return Tensor;\n}();\n\nexports.Tensor = Tensor;\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n  value: function (instance) {\n    return !!instance && instance.dataId != null && instance.shape != null && instance.dtype != null;\n  }\n});\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n */\n\n/** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\nvar Variable =\n/** @class */\nfunction (_super) {\n  __extends(Variable, _super);\n\n  function Variable(initialValue, trainable, name, tensorId) {\n    var _this = _super.call(this, initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId) || this;\n\n    _this.trainable = trainable;\n    _this.name = name;\n    return _this;\n  }\n  /**\n   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n   * the same shape and dtype as the old `tf.Tensor`.\n   *\n   * @param newValue New tensor to be assigned to this variable.\n   */\n\n  /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n\n\n  Variable.prototype.assign = function (newValue) {\n    if (newValue.dtype !== this.dtype) {\n      throw new Error(\"dtype of the new value (\" + newValue.dtype + \") and \" + (\"previous value (\" + this.dtype + \") must match\"));\n    }\n\n    if (!util.arraysEqual(newValue.shape, this.shape)) {\n      throw new Error(\"shape of the new value (\" + newValue.shape + \") and \" + (\"previous value (\" + this.shape + \") must match\"));\n    }\n\n    trackerFn().disposeTensor(this);\n    this.dataId = newValue.dataId;\n    trackerFn().incRef(this, null\n    /* backend */\n    );\n  };\n\n  Variable.prototype.dispose = function () {\n    trackerFn().disposeVariable(this);\n    this.isDisposedInternal = true;\n  };\n\n  return Variable;\n}(Tensor);\n\nexports.Variable = Variable;\nObject.defineProperty(Variable, Symbol.hasInstance, {\n  value: function (instance) {\n    return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;\n  }\n});","map":null,"metadata":{},"sourceType":"script"}